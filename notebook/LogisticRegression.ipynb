{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6cef907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Modules/Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "import warnings\n",
    "#suppress warnings with numpy for sigmoid function\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2f2ba7",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df612c80",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/clean/cleaned_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load datasets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../datasets/clean/cleaned_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../datasets/clean/cleaned_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/19_Projects/dslr/.venv/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/19_Projects/dslr/.venv/lib/python3.8/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/19_Projects/dslr/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/19_Projects/dslr/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/19_Projects/dslr/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/19_Projects/dslr/.venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     is_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/19_Projects/dslr/.venv/lib/python3.8/site-packages/pandas/io/common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    856\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/clean/cleaned_train.csv'"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train = pd.read_csv('../datasets/clean/cleaned_train.csv', index_col = False)\n",
    "test = pd.read_csv('../datasets/clean/cleaned_test.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55aac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7696fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6890b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split X (independent variables) with the target value Y\n",
    "target_columns = ['Gryffindor', 'Hufflepuff', 'Ravenclaw', 'Slytherin']\n",
    "X_train = np.array(train.drop(columns = target_columns))\n",
    "y_train = np.array(train[target_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b813db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The shape of X_train is: ' + str(X_train.shape))\n",
    "print ('The shape of y_train is: ' + str(y_train.shape))\n",
    "print ('We have m = %d training examples' % (len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eee7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Access the ith column \n",
    "y_train[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c91377",
   "metadata": {},
   "source": [
    "### Sigmoid function\n",
    "\n",
    "For logistic regression, the model is represented as\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(x) = g(\\mathbf{w}\\cdot \\mathbf{x} + b)$$\n",
    "where function $g$ is the sigmoid function. The sigmoid function is defined as:\n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8684fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "    Args:\n",
    "        z (ndarray): A scalar, numpy array of any size.\n",
    "    Returns:\n",
    "        g (ndarray): sigmoid(z), with the same shape as z\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33279a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0013e206",
   "metadata": {},
   "source": [
    "### Cost function for logistic regression\n",
    "\n",
    "\n",
    "Recall that for logistic regression, the cost function is of the form \n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m}\\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$\n",
    "\n",
    "where\n",
    "* m is the number of training examples in the dataset\n",
    "\n",
    "\n",
    "* $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ is the cost for a single data point, which is - \n",
    "\n",
    "    $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$\n",
    "    \n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$, which is the actual label\n",
    "\n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(\\mathbf{w} \\cdot \\mathbf{x^{(i)}} + b)$ where function $g$ is the sigmoid function.\n",
    "    * It might be helpful to first calculate an intermediate variable $z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x^{(i)}} + b = w_0x^{(i)}_0 + ... + w_{n-1}x^{(i)}_{n-1} + b$ where $n$ is the number of features, before calculating $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b, lambda_= 1):\n",
    "    \"\"\"\n",
    "    Computes the cost over all examples\n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
    "      y : (array_like Shape (m,)) target value \n",
    "      w : (array_like Shape (n,)) Values of parameters of the model      \n",
    "      b : scalar Values of bias parameter of the model\n",
    "      lambda_: unused placeholder\n",
    "    Returns:\n",
    "      total_cost: (scalar)         cost \n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    \n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "        z = np.dot(X[i],w) + b\n",
    "        f_wb = sigmoid(z)\n",
    "        cost += -y[i]*np.log(f_wb) - (1-y[i])*np.log(1-f_wb)\n",
    "    total_cost = cost/m\n",
    "    \n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319de5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1-y_train[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19649090",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X_train.shape\n",
    "\n",
    "# Compute and display cost with w initialized to zeroes\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0.\n",
    "cost = compute_cost(X_train, y_train[:, 0], initial_w, initial_b)\n",
    "print('Cost at initial w (zeros): {:.3f}'.format(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c4d1e",
   "metadata": {},
   "source": [
    "###  Gradient for logistic regression\n",
    "\n",
    "In this section, you will implement the gradient for logistic regression.\n",
    "\n",
    "Recall that the gradient descent algorithm is:\n",
    "\n",
    "$$\\begin{align*}& \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & b := b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\newline       \\; & w_j := w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{for j := 0..n-1}\\newline & \\rbrace\\end{align*}$$\n",
    "\n",
    "where, parameters $b$, $w_j$ are all updated simultaniously\n",
    "\n",
    "compute $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w}$, $\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$ from equations (2) and (3) below.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)})x_{j}^{(i)} \\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a0605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b, lambda_=None): \n",
    "    \"\"\"\n",
    "    Computes the gradient for logistic regression \n",
    " \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) variable such as house size \n",
    "      y : (array_like Shape (m,1)) actual value \n",
    "      w : (array_like Shape (n,1)) values of parameters of the model      \n",
    "      b : (scalar)                 value of parameter of the model \n",
    "      lambda_: unused placeholder.\n",
    "    Returns\n",
    "      dj_dw: (array_like Shape (n,1)) The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db: (scalar)                The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    dj_dw = np.zeros(w.shape)\n",
    "    dj_db = 0.\n",
    "\n",
    "    z = np.dot(X, w) + b\n",
    "    f_wb = sigmoid(z)\n",
    "    \n",
    "    for j in range(n):\n",
    "        dj_dw[j] = (np.sum(np.dot(f_wb - y, X.T[j])))\n",
    "            \n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = np.sum(f_wb - y) / m\n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d194133",
   "metadata": {},
   "source": [
    "### Learning parameters using gradient descent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters, lambda_): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X :    (array_like Shape (m, n)\n",
    "      y :    (array_like Shape (m,))\n",
    "      w_in : (array_like Shape (n,))  Initial values of parameters of the model\n",
    "      b_in : (scalar)                 Initial value of parameter of the model\n",
    "      cost_function:                  function to compute cost\n",
    "      alpha : (float)                 Learning rate\n",
    "      num_iters : (int)               number of iterations to run gradient descent\n",
    "      lambda_ (scalar, float)         regularization constant\n",
    "      \n",
    "    Returns:\n",
    "      w : (array_like Shape (n,)) Updated values of parameters of the model after\n",
    "          running gradient descent\n",
    "      b : (scalar)                Updated value of parameter of the model after\n",
    "          running gradient descent\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of training examples\n",
    "    m = len(X)\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db, dj_dw = gradient_function(X, y, w_in, b_in, lambda_)   \n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w_in = w_in - alpha * dj_dw\n",
    "        b_in = b_in - alpha * dj_db\n",
    "       \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            cost =  cost_function(X, y, w_in, b_in, lambda_)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters/10) == 0 or i == (num_iters-1):\n",
    "            w_history.append(w_in)\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n",
    "        \n",
    "    return w_in, b_in, J_history, w_history #return w and J,w history for graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033d2dab",
   "metadata": {},
   "source": [
    "## Fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46a2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X_train.shape\n",
    "initial_w = 0.01 * (np.random.rand(n).reshape(-1,1) - 0.5)\n",
    "initial_b = -8\n",
    "\n",
    "\n",
    "# Some gradient descent settings\n",
    "iterations = 10000\n",
    "alpha = 0.01\n",
    "\n",
    "w,b, J_history,_ = gradient_descent(X_train ,y_train[:, 3], initial_w, initial_b, \n",
    "                                   compute_cost, compute_gradient, alpha, iterations, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8da5a11",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27707f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b): \n",
    "    \"\"\"\n",
    "    Predict whether the label is 0 or 1 using learned logistic\n",
    "    regression parameters w\n",
    "    \n",
    "    Args:\n",
    "    X : (ndarray Shape (m, n))\n",
    "    w : (array_like Shape (n,))      Parameters of the model\n",
    "    b : (scalar, float)              Parameter of the model\n",
    "\n",
    "    Returns:\n",
    "    p: (ndarray (m,1))\n",
    "        The predictions for X using a threshold at 0.5\n",
    "    \"\"\"\n",
    "    # number of training examples\n",
    "    m, n = X.shape\n",
    "    p = np.zeros(m)\n",
    "\n",
    "    f_wb = sigmoid(np.dot(X, w) + b)\n",
    "    for i, prob in enumerate(f_wb):\n",
    "        p[i] = 1 if prob >= 0.50 else 0\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d276ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute accuracy on our training set\n",
    "p = predict(X_train, w,b)\n",
    "print('Train Accuracy: %f'%(np.mean(p == y_train[:, 3]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710259b0",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1a58e",
   "metadata": {},
   "source": [
    "# Make a class out of it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3c1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "        A class to perform Logistic Regression\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Define attributes which will be passed later\n",
    "        \"\"\"\n",
    "        # train data and label\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        \n",
    "        # m: number of observations\n",
    "        self.m = None\n",
    "        \n",
    "        # n: number of independent variables (X)\n",
    "        self.n = None\n",
    "        \n",
    "        # store historic value of cost function. init as +infinity\n",
    "        self.costs = [np.inf]\n",
    "\n",
    "        self.J_history = []\n",
    "        self.w_history = []\n",
    "        \n",
    "        # parameteres (weights)\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "        # regularization constant lambda_ (scalar, float)\n",
    "        self.lambda_ = None\n",
    "\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"\n",
    "        Compute the sigmoid of z\n",
    "        Args:\n",
    "            z (ndarray): A scalar, numpy array of any size.\n",
    "        Returns:\n",
    "            g (ndarray): sigmoid(z), with the same shape as z\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    \n",
    "    def compute_cost(self, X, y, w, b):\n",
    "        \"\"\"\n",
    "        Computes the cost over all examples\n",
    "        Args:\n",
    "          X : (ndarray Shape (m,n)) data, m examples by n features\n",
    "          y : (array_like Shape (m,)) target value \n",
    "          w : (array_like Shape (n,)) Values of parameters of the model      \n",
    "          b : scalar Values of bias parameter of the model\n",
    "          lambda_: unused placeholder\n",
    "        Returns:\n",
    "          total_cost: (scalar)         cost \n",
    "        \"\"\"\n",
    "\n",
    "        m, n = X.shape\n",
    "\n",
    "        z = np.dot(X, w) + b\n",
    "        pred = self.sigmoid(z)\n",
    "\n",
    "        pred[pred == 1] = 1-1e-9 #hard cap max threshold\n",
    "        \n",
    "        \n",
    "        cost = np.dot(-y, np.log(pred)) - (np.dot(1 - y, np.log(1 - pred)))\n",
    "        total_cost = np.sum(cost) / m\n",
    "    \n",
    "        reg_cost = np.sum(np.dot(w, w.T))\n",
    "        total_cost = total_cost + (self.lambda_/(2 * m)) * reg_cost\n",
    "        \n",
    "        return total_cost\n",
    "\n",
    "    \n",
    "    def compute_gradient(self, X, y, w, b, lambda_): \n",
    "        \"\"\"\n",
    "        Computes the gradient for logistic regression \n",
    "\n",
    "        Args:\n",
    "          X : (ndarray Shape (m,n)) variable such as house size \n",
    "          y : (array_like Shape (m,1)) actual value \n",
    "          w : (array_like Shape (n,1)) values of parameters of the model      \n",
    "          b : (scalar)                 value of parameter of the model \n",
    "          lambda_: unused placeholder.\n",
    "        Returns\n",
    "          dj_dw: (array_like Shape (n,1)) The gradient of the cost w.r.t. the parameters w. \n",
    "          dj_db: (scalar)                The gradient of the cost w.r.t. the parameter b. \n",
    "        \"\"\"\n",
    "        m, n = X.shape\n",
    "        dj_dw = np.zeros(w.shape)\n",
    "        dj_db = 0.0\n",
    "\n",
    "        z = np.dot(X, w) + b\n",
    "        f_wb = self.sigmoid(z)\n",
    "\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = (np.sum(np.dot(f_wb - y, X.T[j])))\n",
    "\n",
    "        dj_dw = dj_dw / m\n",
    "        dj_dw += np.dot((lambda_ / m), w) # add regularization\n",
    "        dj_db = np.sum(f_wb - y) / m\n",
    "\n",
    "        return dj_db, dj_dw\n",
    "\n",
    "\n",
    "    def gradient_descent(self, cost_function, gradient_function, alpha, num_iters, show_every): \n",
    "        \"\"\"\n",
    "        Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "        num_iters gradient steps with learning rate alpha\n",
    "\n",
    "        Args:\n",
    "          X :    (array_like Shape (m, n)\n",
    "          y :    (array_like Shape (m,))\n",
    "          w_in : (array_like Shape (n,))  Initial values of parameters of the model\n",
    "          b_in : (scalar)                 Initial value of parameter of the model\n",
    "          cost_function:                  function to compute cost\n",
    "          alpha : (float)                 Learning rate\n",
    "          num_iters : (int)               number of iterations to run gradient descent\n",
    "          lambda_ (scalar, float)         regularization constant\n",
    "\n",
    "        Returns:\n",
    "          w : (array_like Shape (n,)) Updated values of parameters of the model after\n",
    "              running gradient descent\n",
    "          b : (scalar)                Updated value of parameter of the model after\n",
    "              running gradient descent\n",
    "        \"\"\"\n",
    "        \n",
    "        w_in = self.w\n",
    "        b_in = self.b\n",
    "        for i in range(num_iters):\n",
    "\n",
    "            # Calculate the gradient and update the parameters\n",
    "            dj_db, dj_dw = gradient_function(self.X, self.y, w_in, b_in, self.lambda_)   \n",
    "\n",
    "            # Update Parameters using w, b, alpha and gradient\n",
    "            w_in = w_in - alpha * dj_dw               \n",
    "            b_in = b_in - alpha * dj_db              \n",
    "\n",
    "            # Save cost J at each iteration\n",
    "            if i<100000:      # prevent resource exhaustion \n",
    "                cost =  cost_function(self.X, self.y, w_in, b_in)\n",
    "\n",
    "            # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "            if i % show_every == 0 or i == num_iters-1:\n",
    "                self.J_history.append(cost)\n",
    "#                 self.w_history.append(self.w)\n",
    "                print(f\"Iteration {i:4}: Cost {float(self.J_history[-1]):8.2f}   \")\n",
    "        self.w = w_in\n",
    "        self.b = b_in\n",
    "        \n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, alpha=0.001, iterations=1500, show_every=None, lambda_= 1):\n",
    "        \"\"\"\n",
    "        setup attributes and apply training\n",
    "        \"\"\"\n",
    "        \n",
    "        # train data and label\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # m: number of observations\n",
    "        self.m, self.n = X.shape\n",
    "\n",
    "        # regularization coefficient\n",
    "        self.lambda_ = lambda_\n",
    "        \n",
    "        # init weights if first call\n",
    "        if type(self.w) is not np.ndarray:\n",
    "            self.w = 0.01 * (np.random.rand(n).reshape(-1,1) - 0.5)\n",
    "        if self.b == None:\n",
    "            self.b = -8\n",
    "        if show_every == None:\n",
    "            show_every = iterations // 10 \n",
    "            \n",
    "        # Perform Gradient Descent\n",
    "        self.gradient_descent(self.compute_cost, self.compute_gradient, alpha, iterations, show_every)\n",
    "\n",
    "    \n",
    "    def predict(self, X, decision_boundary = None): \n",
    "        \"\"\"\n",
    "        Predict whether the label is 0 or 1 using learned logistic\n",
    "        regression parameters w\n",
    "\n",
    "        Args:\n",
    "        X : (ndarray Shape (m, n))\n",
    "        w : (array_like Shape (n,))      Parameters of the model\n",
    "        b : (scalar, float)              Parameter of the model\n",
    "\n",
    "        Returns:\n",
    "        p: (ndarray (m,1))\n",
    "            The predictions for X using a threshold at 0.5\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check if number of features matches our model\n",
    "        \n",
    "        \n",
    "        # number of training examples\n",
    "        m, n = X.shape\n",
    "        p = np.zeros(m)\n",
    "\n",
    "        f_wb = self.sigmoid(np.dot(X, self.w) + self.b)\n",
    "        \n",
    "        if decision_boundary != None:\n",
    "            for i, prob in enumerate(f_wb):\n",
    "                p[i] = 1 if prob >= decision_boundary else 0\n",
    "            return p\n",
    "        \n",
    "        return f_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2c0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88035472",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train[: , 0], alpha=0.00003, iterations=100, lambda_ = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f306b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train[: , 0], alpha=0.000003, iterations=100, lambda_ = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed305b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute accuracy on our training set\n",
    "p = lr.predict(X_train, 0.5)\n",
    "print('Train Accuracy: %f'%(np.mean(p == y_train[:, 0]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907531ca",
   "metadata": {},
   "source": [
    "#### Testing..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d88b883",
   "metadata": {},
   "source": [
    "# Support Multiclass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b45f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLogisticRegression:\n",
    "\n",
    "    def __init__(self):\n",
    "    \n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        \n",
    "        # C: number of categories for Y\n",
    "        # -> create C models and train them each one at teh time\n",
    "        self.c = None\n",
    "        \n",
    "        self.models = []\n",
    "        \n",
    "    def softmax(self, X):\n",
    "        \"\"\"\n",
    "        takes the predicted values from the sub_models\n",
    "        \"\"\"\n",
    "        pred = []\n",
    "        for i in range(self.c):\n",
    "            pred.append(self.models[i].predict(X))\n",
    "        pred = np.array(pred)\n",
    "        res = []\n",
    "        for row in pred.T[0]:\n",
    "            # for each row (student), return the column (house) with the highest probability\n",
    "            res.append(np.argmax(row / np.sum(row)))\n",
    "        res = np.array(res)\n",
    "        return res\n",
    "    \n",
    "    def accuracy(self, pred, true_labels):\n",
    "        \"\"\"\n",
    "        calculate the accuracy of the model prediction given the true labels\n",
    "        \"\"\"\n",
    "        if pred.shape != true_labels.shape:\n",
    "            print('Error in the shape of predictions and true_labels')\n",
    "            return \n",
    "        accuracy = np.mean(pred == true_labels) * 100\n",
    "        print('Accuracy: %f'%(accuracy))\n",
    "        return accuracy\n",
    "    \n",
    "    def score_matrix(self, pred, true_labels):\n",
    "        \"\"\"\n",
    "        calculate scores matrix\n",
    "        \"\"\"\n",
    "        # Calculate overall precision\n",
    "        score_matrix = np.zeros((self.c, self.c))\n",
    "        for i in range(0, len(pred)):\n",
    "            pred_label = pred[i]\n",
    "            true_label = answer[i]\n",
    "            score_matrix[pred_label][true_label] += 1\n",
    "            \n",
    "        precision_per_class = []\n",
    "        for i in range(self.c):\n",
    "            precision_per_class.append(score_matrix[i][i] / score_matrix[i].sum())\n",
    "        \n",
    "        return score_matrix, precision_per_class\n",
    "        \n",
    "    def fit(self, X, y, alpha=0.00003, iterations=100, show_every=None, lambda_= 1):\n",
    "        \"\"\"\n",
    "        setup attributes and apply training\n",
    "        \"\"\"\n",
    "        \n",
    "        # train data and label\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # m: number of observations\n",
    "        self.m, self.n = X.shape\n",
    "        \n",
    "        # c: number of category\n",
    "        self.c = y.shape[1]\n",
    "        \n",
    "        \n",
    "        if show_every == None:\n",
    "            show_every = iterations // 10 \n",
    "        \n",
    "        # init models\n",
    "        if not self.models:\n",
    "            for i in range(self.c):\n",
    "                self.models.append(LogisticRegression())\n",
    "        \n",
    "        # train models\n",
    "        decision_boundary = 0.5\n",
    "        for i in range(self.c):\n",
    "            model = self.models[i]\n",
    "            print(f\"training model {i+1} with alpha= {0.00003}\")\n",
    "            model.fit(X_train, y_train[: , i], alpha=0.00003, iterations=100, lambda_ = 1)\n",
    "            p = model.predict(X_train, decision_boundary)\n",
    "            print('Train Accuracy: %f'%(np.mean(p == y_train[:, i]) * 100))\n",
    "            \n",
    "            print(f\"training model {i+1} with alpha= {0.00001}\")\n",
    "            model.fit(X_train, y_train[: , i], alpha=0.00001, iterations=100, lambda_ = 1)\n",
    "            \n",
    "            p = model.predict(X_train, decision_boundary)\n",
    "            print('Train Accuracy: %f'%(np.mean(p == y_train[:, i]) * 100))\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.softmax(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac94605",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = MultipleLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc30fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models.fit(X_train, y_train, lambda_=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb31c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models.models[1].fit(X_train, y_train[:, 1], alpha=0.00001, iterations=100, lambda_ = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab2454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(models.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1025ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02213c9",
   "metadata": {},
   "source": [
    "### Get true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfbb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "for row in y_train:\n",
    "    answer.append(np.argmax(row))\n",
    "answer = np.array(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute accuracy on our training set\n",
    "print('Train Accuracy: %f'%(np.mean(pred == answer) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295296f",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f314c411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1400/1*eS4zV29dd9vFo0KQSk8s7w.png\" width=\"500\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://miro.medium.com/max/1400/1*eS4zV29dd9vFo0KQSk8s7w.png\", width=500, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_matrix, precision = models.score_matrix(pred, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf362880",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186756dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"global precision = \", sum(precision)/len(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377837d6",
   "metadata": {},
   "source": [
    "## Trying prediction on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5298c8",
   "metadata": {},
   "source": [
    "Reconvert Array of Integer (category number) to 4 arrays of 0and1 for each House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d472e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(test)\n",
    "test_pred = models.softmax(X_test)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.zeros((len(test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c934ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_pred, columns=['Hogwarts House'])\n",
    "target_columns = ['Gryffindor', 'Hufflepuff', 'Ravenclaw', 'Slytherin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a55c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    idx = df['Hogwarts House'][i]\n",
    "    df['Hogwarts House'][i] = target_columns[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Index'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce2ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfea2fe",
   "metadata": {},
   "source": [
    "### Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a10c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e50c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
